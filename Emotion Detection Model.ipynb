{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e85043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 7480\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def read_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r')as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            label = ' '.join(line[1:line.find(\"]\")].strip().split())\n",
    "            text = line[line.find(\"]\")+1:].strip()\n",
    "            data.append([label, text])\n",
    "    return data\n",
    "\n",
    "file = 'text.txt'\n",
    "data = read_data(file)\n",
    "print(\"Number of instances: {}\".format(len(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a28a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "def ngram(token, n): \n",
    "    output = []\n",
    "    for i in range(n-1, len(token)): \n",
    "        ngram = ' '.join(token[i-n+1:i+1])\n",
    "        output.append(ngram) \n",
    "    return output\n",
    "\n",
    "def create_feature(text, nrange=(1, 1)):\n",
    "    text_features = [] \n",
    "    text = text.lower() \n",
    "    text_alphanum = re.sub('[^a-z0-9#]', ' ', text)\n",
    "    for n in range(nrange[0], nrange[1]+1): \n",
    "        text_features += ngram(text_alphanum.split(), n)    \n",
    "    text_punc = re.sub('[a-z0-9]', ' ', text)\n",
    "    text_features += ngram(text_punc.split(), 1)\n",
    "    return Counter(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e141e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "def convert_label(item, name): \n",
    "    items = list(map(float, item.split()))\n",
    "    label = \"\"\n",
    "    for idx in range(len(items)): \n",
    "        if items[idx] == 1: \n",
    "            label += name[idx] + \" \"\n",
    "    \n",
    "    return label.strip()\n",
    "\n",
    "emotions = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "\n",
    "X_all = []\n",
    "y_all = []\n",
    "for label, text in data:\n",
    "    y_all.append(convert_label(label, emotions))\n",
    "    X_all.append(create_feature(text, nrange=(1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a78447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state = 123)\n",
    "\n",
    "def train_test(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, clf.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vectorizer = DictVectorizer(sparse = True)\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ab5640b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Classifier                | Training Accuracy | Test Accuracy |\n",
      "| ------------------------- | ----------------- | ------------- |\n",
      "| SVC                       |         0.9067513 |     0.4512032 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python39\\lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| LinearSVC                 |         0.9988302 |     0.5768717 |\n",
      "| RandomForestClassifier    |         0.9988302 |     0.5541444 |\n",
      "| DecisionTreeClassifier    |         0.9988302 |     0.4585561 |\n"
     ]
    }
   ],
   "source": [
    "#4 models\n",
    "svc = SVC()\n",
    "lsvc = LinearSVC(random_state=123)\n",
    "rforest = RandomForestClassifier(random_state=123)\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "clifs = [svc, lsvc, rforest, dtree]\n",
    "\n",
    "# train and test them \n",
    "print(\"| {:25} | {} | {} |\".format(\"Classifier\", \"Training Accuracy\", \"Test Accuracy\"))\n",
    "print(\"| {} | {} | {} |\".format(\"-\"*25, \"-\"*17, \"-\"*13))\n",
    "for clf in clifs: \n",
    "    clf_name = clf.__class__.__name__\n",
    "    train_acc, test_acc = train_test(clf, X_train, X_test, y_train, y_test)\n",
    "    print(\"| {:25} | {:17.7f} | {:13.7f} |\".format(clf_name, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9daea5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
      "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
      "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
      "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
      "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
     ]
    }
   ],
   "source": [
    "#detecting emotion\n",
    "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "l.sort()\n",
    "label_freq = {}\n",
    "for label, _ in data: \n",
    "    label_freq[label] = label_freq.get(label, 0) + 1\n",
    "\n",
    "# print the labels and their counts in sorted order \n",
    "for l in sorted(label_freq, key=label_freq.get, reverse=True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e248169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This looks so impressive ğŸ˜³\n",
      "I am proud of you ğŸ˜¢\n",
      "My dog passed away yesterday ğŸ˜¢\n",
      "It is so nice to see you! ğŸ˜‚\n"
     ]
    }
   ],
   "source": [
    "#emoji assignment\n",
    "emoji_dict = {\"joy\":\"ğŸ˜\", \"fear\":\"ğŸ˜±\", \"anger\":\"ğŸ˜ \", \"sadness\":\"ğŸ˜¢\", \"disgust\":\"ğŸ˜’\", \"shame\":\"ğŸ˜\", \"guilt\":\"ğŸ˜³\"}\n",
    "t1 = input(\"Enter journal note 1: \")\n",
    "t2 = input(\"Enter journal note 2: \")\n",
    "t3 = input(\"Enter journal note 3: \")\n",
    "t4 = input(\"Enter journal note 4: \")\n",
    "\n",
    "texts = [t1, t2, t3, t4]\n",
    "for text in texts: \n",
    "    features = create_feature(text, nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    prediction = clf.predict(features)[0]\n",
    "    print( text,emoji_dict[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842b61e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a journal note: I had a great day today\n",
      "Enter a journal note: Her dog is sick\n",
      "Enter a journal note: Eww no one likes broccoli\n",
      "Enter a journal note: HOW DARE YOU\n",
      "I had a great day today ğŸ˜‚\n",
      "Her dog is sick ğŸ˜³\n",
      "Eww no one likes broccoli ğŸ˜³\n",
      "HOW DARE YOU ğŸ˜³\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1797de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter journal note 1: I'm sorry i could do nothing\n",
      "Enter journal note 2: That's sickening!\n",
      "Enter journal note 3: She was really worried\n",
      "Enter journal note 4: He just sat alone all day\n",
      "I'm sorry i could do nothing ğŸ˜³\n",
      "That's sickening! ğŸ˜’\n",
      "She was really worried ğŸ˜³\n",
      "He just sat alone all day ğŸ˜’\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebddd646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# her dad passed away \n",
    "# It was so great to see her!\n",
    "# I'm sorry I couldn't do anything\n",
    "# That's really sickening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eac8e240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy       (1. 0. 0. 0. 0. 0. 0.)  1084\n",
      "anger     (0. 0. 1. 0. 0. 0. 0.)  1080\n",
      "sadness   (0. 0. 0. 1. 0. 0. 0.)  1079\n",
      "fear      (0. 1. 0. 0. 0. 0. 0.)  1078\n",
      "disgust   (0. 0. 0. 0. 1. 0. 0.)  1057\n",
      "guilt     (0. 0. 0. 0. 0. 0. 1.)  1057\n",
      "shame     (0. 0. 0. 0. 0. 1. 0.)  1045\n"
     ]
    }
   ],
   "source": [
    "#detecting emotion\n",
    "l = [\"joy\", 'fear', \"anger\", \"sadness\", \"disgust\", \"shame\", \"guilt\"]\n",
    "l.sort()\n",
    "label_freq = {}\n",
    "for label, _ in data: \n",
    "    label_freq[label] = label_freq.get(label, 0) + 1\n",
    "\n",
    "# print the labels and their counts in sorted order \n",
    "for l in sorted(label_freq, key = label_freq.get, reverse = True):\n",
    "    print(\"{:10}({})  {}\".format(convert_label(l, emotions), l, label_freq[l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efc67650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter journal note 1: Her dad passed away\n",
      "Enter journal note 2: It was so great to see you!\n",
      "Enter journal note 3: I'm sorry I couldn't do anything\n",
      "Enter journal note 4: That's really sickening\n",
      "Her dad passed away ğŸ˜¢\n",
      "It was so great to see you! ğŸ˜’\n",
      "I'm sorry I couldn't do anything ğŸ˜³\n",
      "That's really sickening ğŸ˜ \n"
     ]
    }
   ],
   "source": [
    "#emoji assignment\n",
    "emoji_dict = {\"joy\":\"ğŸ˜\", \"fear\":\"ğŸ˜±\", \"anger\":\"ğŸ˜ \", \"sadness\":\"ğŸ˜¢\", \"disgust\":\"ğŸ˜’\", \"shame\":\"ğŸ˜\", \"guilt\":\"ğŸ˜³\"}\n",
    "t1 = input(\"Enter journal note 1: \")\n",
    "t2 = input(\"Enter journal note 2: \")\n",
    "t3 = input(\"Enter journal note 3: \")\n",
    "t4 = input(\"Enter journal note 4: \")\n",
    "\n",
    "texts = [t1, t2, t3, t4]\n",
    "for text in texts: \n",
    "    features = create_feature(text, nrange=(1, 4))\n",
    "    features = vectorizer.transform(features)\n",
    "    prediction = clf.predict(features)[0]\n",
    "    print( text, emoji_dict[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517412e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
